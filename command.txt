# Sqoop has a good user guide which describe all the commands and options
https://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html

#basic database operation in mysql

--the -u option is for user id which is root by default in mysql
-- the -p is for the password, we can either specify the password or leave it, then it will prompt.

-- Step 1
mysql -u root -p
mysql -u root -pcloudera

-- Step 2 : once we are inside the mysql command prompt, then we have to list the schemas and tables
show schemas;
use retail_db;
show tables;

--once we know the schema and table, then we can try to describle the table.
desc products;

--select statements will be same as any other standard sql
select count(*) from products;
select * from productcs limit 10;
select * from products limit 2 \G; -- this option will give column items as row format. 

************************************************************
The structure of the sqoop command 
************************************************************
1) Everything start with sqoop
2) followed by command like import/export/list-databases etc
3) followed by arguments with -- indicator


-- How to use list command using sqoop to get the list of databases.
sqoop list-databases \
  --connect jdbc:mysql://localhost:3306 \
  --username root \
  --password cloudera
  
--how to list the tables
sqoop list-tables \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera
  
Eval command
-------------
Any valid SQL query or command can be run using sqoop eval. 
It is primarily used to load or query log tables while running Sqoop jobs at regular intervals

sqoop eval \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --query "SELECT * FROM order_items LIMIT 10"

sqoop eval \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --query "INSERT INTO orders VALUES (100000, '2017-10-31 00:00:00.0', 100000, 'DUMMY')"

sqoop eval \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --query "CREATE TABLE dummy (i INT)"

sqoop eval \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --query "INSERT INTO dummy VALUES (1)"
  
  
Import Data
-----------


sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db
  
  sqoop import \
  --connect jdbc:mysql://localhost:3306:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items \
  --target-dir /user/cloudera/landing_zone/sqoop_import/order_items
  
  
--warehouse-dir : It create a directory which works as database directory (sqoop_db_movies) and table name (as given in import command) directory automatically created with imported files with in warehouse dir(database directory).
--target-dir: It create a directory which work as table name (sqoop_table_movies) with imported files.

Here is the execution lifecycle of Sqoop.

1.Connect to the source database and get metadata
2.Generate java file with metadata and compile to a jar file
3.Apply boundaryvalsquery to apply split logic, default 4
4.Use split boundaries to issue queries against the source database
5.Each thread will have a different connection to issue the query
6.Each thread will get a mutually exclusive subset of the data
7.Data will be written to HDFS in a separate file per thread


sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db \
  --num-mappers 1 \
  --delete-target-dir

 sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db \
  --num-mappers 1 \
  --append
  
------------------------------
Managing Directories
------------------------------
1) By default sqoop import fails if target directory already exists
2) Directory can be overwritten by using –delete-target-dir
3) Data can be appended to existing directories by saying –append


sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db \
  --num-mappers 1 \
  --delete-target-dir

 sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db \
  --num-mappers 1 \
  --append
  
------------------------------
  Importing Data
------------------------------
1)Number of mappers
2)Splitting using a custom column
3)Splitting using non-numeric column
4)Let us explore how we can customize split logic

By default number of mappers is 4, it can be changed with –num-mappers

1) Split logic will be applied to a primary key if exists
2) If primary key does not exist and if we use a number of mappers more than 1, then sqoop import will fail
3) At that time we can use –split-by to split on a non-key column or explicitly set –num-mappers to 1 or use –auto-reset-to-one-mapper
4) If the primary key column or the column specified in split-by clause is non numeric type, then we need to use this additional argument -Dorg.apache.sqoop.splitter.allow_text_splitter=true

Using split-by
---------------
1)For performance, reason choose a column which is indexed as part of the split-by clause
2)If there are null values in the column, corresponding records from the table will be ignored
3)Data in the split-by column need not be unique, but if there are duplicates then there can be a skew in the data while importing (which means some files might be relatively bigger compared to other files)

sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items_nopk \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db \
  --split-by order_item_order_id
  
#Splitting on text field
sqoop import \
  -Dorg.apache.sqoop.splitter.allow_text_splitter=true \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table orders \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db \
  --split-by order_status
  
  
-------------------------
Different File Format
-------------------------
File formats
  Text file (default)
  Sequence file
  Avro file
  Parquet file
  
  sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db \
  --num-mappers 2 \
  --as-sequencefile
  
  
----------------------------
Compression
----------------------------
1) Go to /etc/hadoop/conf and check core-site.xml for supported compression codecs
2) Use –compress to enable compression
3) If compression codec is not specified, it will use gzip by default
4) Compression algorithm can be specified using compression-codec
5) To uncompress the file use the command gunzip.


sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db \
  --num-mappers 2 \
  --as-textfile \
  --compress \
  --compression-codec org.apache.hadoop.io.compress.GzipCodec

sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db \
  --num-mappers 2 \
  --as-textfile \
  --compress \
  --compression-codec org.apache.hadoop.io.compress.SnappyCodec
  
  -----------------------------------------
  What is Boundary Value Query in Sqoop
  -----------------------------------------
  Sqoop runs it mapper task by executing the SQL like SELECT * FROM table WHERE id >= low AND id < high. Sqoop uses query select minimum value for splitting, a maximum value for splitting to find out boundaries for creating splits. This Sqoop operation is known as Boundary Value Query.
  
  sqoop import \
--connect jdbc:mysql://localhost:3306/retail_db \
--username root \
--password cloudera \
--table order_items \
--warehouse-dir /user/cloudera/landing_zone/sqoop_import/reatil_db \
--boundary-query 'select min(order_item_id), max(order_item_id) from order_items where order_item_id > 99999'

-----------------------------------------------
Transformations and filtering
-----------------------------------------------
sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --table order_items \
  --columns order_item_order_id,order_item_id,order_item_subtotal \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/retail_db \
  --num-mappers 2
  
  
  sqoop import \
  --connect jdbc:mysql://localhost:3306/retail_db \
  --username root \
  --password cloudera \
  --target-dir /user/cloudera/landing_zone/sqoop_import/orders_with_revenue \
  --num-mappers 2 \
  --query "select o.*, sum(oi.order_item_subtotal) order_revenue from orders o join order_items oi on o.order_id = oi.order_item_order_id and \$CONDITIONS group by o.order_id, o.order_date, o.order_customer_id, o.order_status" \
  --split-by order_id
Columns
Query


-------------------------------------------
Delimiters and handling nulls
-------------------------------------------
#Default behavior
sqoop import \
  --connect jdbc:mysql://localhost:3306/hr_db \
  --username root \
  --password cloudera \
  --table employees \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/hr_db
  
#Changing default delimiters and nulls
sqoop import \
  --connect jdbc:mysql://localhost:3306/hr_db \
  --username root \
  --password cloudera \
  --table employees \
  --warehouse-dir /user/cloudera/landing_zone/sqoop_import/hr_db \
  --null-non-string -1 \
  --fields-terminated-by "\000" \
  --lines-terminated-by ":"

---------------------------------------------
  Incremental loads can be performed using
---------------------------------------------
1) query
2) where
3) Standard incremental loads

# Baseline import
sqoop import \
  --connect jdbc:mysql://locahost:3306/retail_db \
  --username root \
  --password cloudera\
  --target-dir /user/cloudera/landing_zone/sqoop_import/retail_db/orders \
  --num-mappers 2 \
  --query "select * from orders where \$CONDITIONS and order_date like '2013-%'" \
  --split-by order_id

# Query can be used to load data based on condition
sqoop import \
  --connect jdbc:mysql://locahost:3306/retail_db \
  --username root \
  --password cloudera\
  --target-dir /user/cloudera/landing_zone/sqoop_import/retail_db/orders \
  --num-mappers 2 \
  --query "select * from orders where \$CONDITIONS and order_date like '2014-01%'" \
  --split-by order_id \
  --append

# where in conjunction with table can be used to get data based up on a condition
sqoop import \
  --connect jdbc:mysql://locahost:3306/retail_db \
  --username root \
  --password cloudera\
  --target-dir /user/cloudera/landing_zone/sqoop_import/retail_db/orders \
  --num-mappers 2 \
  --table orders \
  --where "order_date like '2014-02%'" \
  --append

# Incremental load using arguments specific to incremental load
sqoop import \
  --connect jdbc:mysql://locahost:3306/retail_db \
  --username root \
  --password cloudera\
  --target-dir /user/cloudera/landing_zone/sqoop_import/retail_db/orders \
  --num-mappers 2 \
  --table orders \
  --check-column order_date \
  --incremental append \
  --last-value '2014-02-28'